{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...welcome back!\n",
    "\n",
    "\n",
    "# TITANIC Part II\n",
    "\n",
    "## Machine Learning from Disaster: Introduction to `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas.io.sql as pd_sql\n",
    "import sqlite3 as sql\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-establish database connection\n",
    "con = sql.connect(\"titanic.db\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('titanic',), ('training_data',)]\n"
     ]
    }
   ],
   "source": [
    "# Figure out the name of the table you saved your data to\n",
    "cursor = con.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract everything from the 'training_data' table (or whatever you called it) into a dataframe\n",
    "train = pd_sql.read_sql('select * from training_data', con, index_col='index').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  PassengerId  Survived  Pclass  \\\n",
       "0      0            1         0       3   \n",
       "1      1            2         1       1   \n",
       "2      2            3         1       3   \n",
       "3      3            4         1       1   \n",
       "4      4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch     Fare Embarked  \n",
       "0      0   7.2500        S  \n",
       "1      0  71.2833        C  \n",
       "2      0   7.9250        S  \n",
       "3      0  53.1000        S  \n",
       "4      0   8.0500        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is it all still here?\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Model: A Naive Approach    \n",
    "\n",
    "Let's start by creating a model that predicts purely based on gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportion of passengers who survived is 0.3838383838383838.\n"
     ]
    }
   ],
   "source": [
    "# Set some variables\n",
    "number_passengers = train.shape[0] \n",
    "number_survived = len(train[train.Survived == 1])\n",
    "\n",
    "# What proportion of the passengers survived?\n",
    "proportion_survived = float(number_survived) / number_passengers\n",
    "print('The proportion of passengers who survived is %s.' % proportion_survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportion of women who survived is 0.7420382165605095.\n",
      "The proportion of men who survived is 0.18890814558058924.\n"
     ]
    }
   ],
   "source": [
    "# How can we determine what proportion of the women and of the men who survived?\n",
    "# Let's start by segregating the men and women\n",
    "women = train[train.Sex == \"female\"]\n",
    "men = train[train.Sex != \"female\"]\n",
    "\n",
    "# Determine the proportion of women who survived\n",
    "proportion_women_survived = float(len(women[women.Survived == 1])) / len(women)\n",
    "print('The proportion of women who survived is %s.' % proportion_women_survived)\n",
    "\n",
    "# Determine the proportion of men who survived\n",
    "proportion_men_survived = float(len(men[men.Survived == 1])) / len(men)\n",
    "print('The proportion of men who survived is %s.' % proportion_men_survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we know that women were MUCH more likely to survive, and we could just say that our model is:\n",
    "- if female => survived = 1\n",
    "- if male => survived = 0\n",
    "\n",
    "But that means our predictions are going to be wrong sometimes -- for about a quarter of the women and a fifth of the men. Let's use the Python library Scikit-learn to see if we can do a little better!\n",
    "\n",
    "## Using `scikit-learn`\n",
    "\n",
    "`Scikit-learn` is a powerful machine learning library implemented in Python with numeric and scientific computing powerhouses `NumPy`, `SciPy`, and `matplotlib` for extremely fast analysis of small to medium-sized data sets. It is open source, commercially usable and contains many modern machine learning algorithms for classification, regression, clustering, feature extraction, and optimization. For this reason, `scikit-learn` is often the first tool in a data scientist's toolkit for machine learning of incoming data sets.\n",
    "\n",
    "`Scikit-learn` will expect numeric values and no blanks, so first we need to do a bit more wrangling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Sex' is stored as a text value. We should convert (or 'map') it into numeric binaries \n",
    "# so it will be ready for scikit-learn.\n",
    "train['Sex'] = train['Sex'].map({'male': 0,'female': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare  \\\n",
       "0      0            1         0       3    0  22.0      1      0   7.2500   \n",
       "1      1            2         1       1    1  38.0      1      0  71.2833   \n",
       "2      2            3         1       3    1  26.0      0      0   7.9250   \n",
       "3      3            4         1       1    1  35.0      1      0  53.1000   \n",
       "4      4            5         0       3    0  35.0      0      0   8.0500   \n",
       "\n",
       "  Embarked  \n",
       "0        S  \n",
       "1        C  \n",
       "2        S  \n",
       "3        S  \n",
       "4        S  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we've got a table of purely numeric data with no null values. We're ready to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION\n",
    "\n",
    "A logistic regression mathematically calculates the decision boundary between the possibilities. It looks for a straight line that represents a cutoff that most accurately represents the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ! To do ! \n",
    "\n",
    "you have to change the path between pd.read_csv(\"....path....\") to the path to the test csv on your repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../titanic/data/test.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "\n",
    "test[\"Age\"] = test[\"Age\"].fillna(train[\"Age\"].median())\n",
    "\n",
    "test.loc[test[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "test.loc[test[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "\n",
    "test = test.drop(['Cabin'], axis=1)\n",
    "test = test.drop(['Embarked'], axis=1)\n",
    "test = test.drop(['Name'], axis=1)\n",
    "test = test.drop(['Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our algorithm\n",
    "lr = LogisticRegression(random_state=1, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our predictors\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\"]\n",
    "expected  = train[\"Survived\"]\n",
    "\n",
    "# Train the algorithm using all the training data\n",
    "lr.fit(train[predictors], expected)\n",
    "\n",
    "# Make predictions using the training set -- where we already know the correct answers\n",
    "predicted = lr.predict(train[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1\n",
       "5          897         0\n",
       "6          898         1\n",
       "7          899         0\n",
       "8          900         1\n",
       "9          901         0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions based on the test data\n",
    "predictions = lr.predict(test[predictors])\n",
    "\n",
    "# Frame your submission for Kaggle\n",
    "test_predictions = pd.DataFrame({\n",
    "        \"PassengerId\": test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "\n",
    "test_predictions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that was easy! But how can we find out how well it worked?\n",
    "\n",
    "### Cross-Validation   \n",
    "\n",
    "For Kaggle, the training samples are constructed by splitting our original dataset into more than one part. But what if certain chunks of our data have more variance than others? We want to ensure that our model performs just as well regardless of the particular way the data are divided up. So let's go back and do some cross-validation splits.    \n",
    "\n",
    "More on cross-validation tools inside scikit-learn here:    \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[[\"Pclass\", \"Sex\", \"Age\", \"SibSp\"]]\n",
    "y = train[\"Survived\"]\n",
    "\n",
    "# Split your data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the training data to the model\n",
    "log_reg = lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7988826815642458"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Every estimator has a score method that can judge the quality of the \n",
    "# fit (or the prediction) on new data. Bigger is better.   \n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also ask for a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Perished       0.81      0.86      0.83       105\n",
      "    Survived       0.78      0.72      0.75        74\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.80      0.79      0.79       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "expected   = y_test\n",
    "predicted  = log_reg.predict(X_test)\n",
    "classificationReport = classification_report(expected, predicted, target_names=[\"Perished\", \"Survived\"])\n",
    "print(classificationReport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do I interpret this report?\n",
    "    \n",
    "Precision is the number of correct positive results divided by the number of all positive results (e.g. how many of the passengers we predicted would survive actually did survive?).\n",
    "\n",
    "Recall is the number of correct positive results divided by the number of positive results that should have been returned (e.g. how many of the passengers who did survive did we accurately predict would survive?). \n",
    "\n",
    "The F1 score is a measure of a test's accuracy. It considers both the precision and the recall of the test to compute the score. The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst at 0.    \n",
    "\n",
    "    precision = true positives / (true positives + false positives)\n",
    "\n",
    "    recall = true positives / (false negatives + true positives)\n",
    "\n",
    "    F1 score = 2 * ((precision * recall) / (precision + recall))\n",
    "    \n",
    "So how well did our Logistic Regression Model do?    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions based on the test data\n",
    "predictions = log_reg.predict(test[predictors])\n",
    "\n",
    "# Frame your 2nd submission to Kaggle\n",
    "kgl_submission_lr = pd.DataFrame({\n",
    "        \"PassengerId\": test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "\n",
    "kgl_submission_lr.to_csv('lr_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST    \n",
    "\n",
    "Some models will work better than others! Let's try another one.    \n",
    "\n",
    "A random forest is a 'meta estimator'. It will fit a number of decision trees (we'll have to tell it how many) on various sub-samples of the dataset. Then it will use averaging to improve the predictive accuracy and control over-fitting.    \n",
    "\n",
    "Read more about Random Forests here:    \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll select 50 trees and opt for 'out-of-bag' samples to estimate the generalization error.\n",
    "rf = RandomForestClassifier(n_estimators=50, oob_score=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=50, oob_score=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next split your data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# ...and then run the 'fit' method to build a forest of trees\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7541899441340782"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Perished       0.75      0.84      0.79        98\n",
      "    Survived       0.77      0.65      0.71        81\n",
      "\n",
      "    accuracy                           0.75       179\n",
      "   macro avg       0.76      0.75      0.75       179\n",
      "weighted avg       0.76      0.75      0.75       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "expected   = y_test\n",
    "predicted  = rf.predict(X_test)\n",
    "classificationReport = classification_report(expected, predicted, target_names=[\"Perished\", \"Survived\"])\n",
    "print(classificationReport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how did we do with our Random Forest Classifier? Sometimes visualizations can\n",
    "help us to interpret our results. Here is a function that will take our classification\n",
    "report and create a color-coded heat map that tells us where our model is strong (deep\n",
    "reds) and/or weak (lighter pinks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_report(cr, title='Classification report', cmap=plt.cm.Reds):\n",
    "\n",
    "    lines = cr.split('\\n')\n",
    "    classes = []\n",
    "    plotMat = []\n",
    "\n",
    "    for line in lines[2 : (len(lines) - 5)]:\n",
    "        t = line.split()\n",
    "        classes.append(t[0])\n",
    "        v = [float(x) for x in t[1: len(t) - 1]]\n",
    "        plotMat.append(v)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    fig = plt.imshow(plotMat, interpolation='nearest', cmap=cmap)\n",
    "    \n",
    "    for c in range(len(plotMat)+1):\n",
    "        for r in range(len(classes)):\n",
    "            try:\n",
    "                txt = plotMat[r][c]\n",
    "                ax.text(c,r,plotMat[r][c],va='center',ha='center')\n",
    "            except IndexError:\n",
    "                pass\n",
    "            \n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    x_tick_marks = np.arange(3)\n",
    "    y_tick_marks = np.arange(len(classes)-1)\n",
    "    plt.xticks(x_tick_marks, ['precision', 'recall', 'f1-score'], rotation=45)\n",
    "        \n",
    "    plt.yticks(y_tick_marks, classes)\n",
    "   \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Classes')\n",
    "    plt.xlabel('Measures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (1), usually from a call to set_ticks, does not match the number of ticklabels (2).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-75860591a3bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_classification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassificationReport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-380550a90114>\u001b[0m in \u001b[0;36mplot_classification_report\u001b[0;34m(cr, title, cmap)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tick_marks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f1-score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tick_marks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36myticks\u001b[0;34m(ticks, labels, **kwargs)\u001b[0m\n\u001b[1;32m   1700\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_yticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1703\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_set_ticklabels\u001b[0;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfontdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_keyword_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3.2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"minor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[0;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1713\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m                 raise ValueError(\n\u001b[0;32m-> 1715\u001b[0;31m                     \u001b[0;34m\"The number of FixedLocator locations\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1716\u001b[0m                     \u001b[0;34mf\" ({len(locator.locs)}), usually from a call to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m                     \u001b[0;34m\" set_ticks, does not match\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (1), usually from a call to set_ticks, does not match the number of ticklabels (2)."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_classification_report(classificationReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions based on the test data\n",
    "predictions = rf.predict(test[predictors])\n",
    "\n",
    "# Frame your 3rd submission to Kaggle\n",
    "kgl_submission_rf = pd.DataFrame({\n",
    "        \"PassengerId\": test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "\n",
    "kgl_submission_rf.to_csv('rf_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM    \n",
    "\n",
    "Support vector machines use points in transformed problem space to separate the classes into groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['linear', 'poly', 'rbf']\n",
    "\n",
    "splits = train_test_split(X,y, test_size=0.2)\n",
    "X_train, X_test, y_train, y_test = splits\n",
    "\n",
    "for kernel in kernels:\n",
    "    if kernel != 'poly':\n",
    "        model      = SVC(kernel=kernel, gamma='auto')\n",
    "    else:\n",
    "        model      = SVC(kernel=kernel, degree=3, gamma='auto')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "expected   = y_test\n",
    "predicted  = model.predict(X_test)\n",
    "\n",
    "SVC_report = classification_report(expected, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classification_report(SVC_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, predicted)  \n",
    "decision_threshold = np.append(thresholds, 1)\n",
    "\n",
    "plt.plot(decision_threshold, precision, color='red')  \n",
    "plt.plot(decision_threshold, recall, color='blue')  \n",
    "leg = plt.legend(('precision', 'recall'), frameon=True)  \n",
    "leg.get_frame().set_edgecolor('k')  \n",
    "plt.xlabel('decision_threshold')  \n",
    "plt.ylabel('%')  \n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions based on the test data\n",
    "predictions = model.predict(test[predictors])\n",
    "\n",
    "# Frame your 4th submission to Kaggle\n",
    "kgl_submission_svm = pd.DataFrame({\n",
    "        \"PassengerId\": test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "\n",
    "kgl_submission_svm.to_csv('svm_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So of the four methods - our naive model, as well as Logistic Regression, Random Forest, and SVM, which one performed the best on this data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources and Further Reading    \n",
    "\n",
    "This tutorial is based on the Kaggle Competition, \"Predicting Survival Aboard the Titanic\"    \n",
    "https://www.kaggle.com/c/titanic    \n",
    "\n",
    "As well as the following tutorials:       \n",
    "https://www.kaggle.com/alexisbcook/titanic-tutorial  \n",
    "https://github.com/savarin/pyconuk-introtutorial/tree/master/notebooks    \n",
    "\n",
    "See also:    \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html   \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html   \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html  \n",
    "https://scikit-learn.org/stable/modules/svm.html   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
